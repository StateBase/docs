---
title: "Vercel AI SDK"
description: "Streaming support with Next.js"
---

Use `onFinish` to log turns asynchronously.

```typescript
import { OpenAIStream, StreamingTextResponse } from 'ai';
import { StateBase } from '@statebase/client';

export async function POST(req: Request) {
  const { messages } = await req.json();
  const sb = new StateBase({ apiKey: process.env.SB_KEY });
  
  const response = await openai.chat.completions.create({
    model: 'gpt-4',
    stream: true,
    messages
  });

  const stream = OpenAIStream(response, {
    onFinish: async (completion) => {
      await sb.sessions.addTurn({
          sessionId: 'sess_123',
          input: messages[messages.length - 1].content,
          output: completion
      });
    }
  });

  return new StreamingTextResponse(stream);
}
```
