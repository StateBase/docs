---
title: "Introduction"
description: "Understand AI context, memory, and how StateBase helps you build reliable, context-aware LLMs and agents."
---

## Overview

StateBase is the **context layer** for LLMs and AI agents. It helps you store, retrieve, and apply context so AI systems stay accurate, relevant, and consistent over time.

If you’ve ever struggled with:
*   ❌ Stateless LLM responses
*   ❌ Prompt stuffing
*   ❌ Fragile RAG pipelines
*   ❌ Agents that "forget" users or past actions

**StateBase is built to solve exactly that.**

## What problem does StateBase solve?

Large language models don't remember anything by default. Every request starts from scratch unless you:
1.  **Manually inject context**
2.  **Rebuild memory systems**
3.  **Orchestrate retrieval logic yourself**

This quickly becomes brittle, expensive, and hard to scale. StateBase makes **context a first-class system capability**.

## What is StateBase?

StateBase is a **developer-first infrastructure** for AI context management. It gives you a reliable way to:

1.  **Store** application, user, and workflow context as raw facts.
2.  **Retrieve** the most relevant information based on the query.
3.  **Feed** that context into LLMs and agents.

All without writing custom memory or retrieval infrastructure.

## Why use StateBase instead of rolling your own?

| Feature | Roll Your Own | StateBase |
| :--- | :--- | :--- |
| **Architecture** | Custom vector plumbing | Clean API, no glue code |
| **AI Output** | Hallucinations common | Grounded, relevant responses |
| **Speed** | Weeks of dev time | Minutes with SDKs |
| **Reliability** | Prototype quality | Production-grade SLA |

## How StateBase Works

StateBase sits between your Data and your LLM.

<Steps>
  <Step title="Ingest Context">
    Store data from users, files, APIs, or application events.
  </Step>
  <Step title="Index & Organize">
    Context is structured into a Knowledge Graph for fast, relevant retrieval.
  </Step>
  <Step title="Search">
    Retrieve only the most useful context for a specific user request.
  </Step>
  <Step title="Use with LLM">
    Pass retrieved context into prompts or agent logic via the SDK.
  </Step>
  <Step title="Persist">
    Automatically update memory as users and workflows evolve.
  </Step>
</Steps>

## Who is this for?

StateBase is built for:
*   **Developers** building autonomous agents.
*   **Teams** shipping LLM-powered SaaS products.
*   **Engineers** tired of maintaining fragile RAG pipelines.

## Why StateBase?

Most AI systems break as context grows. We don't. StateBase operates at the **Pareto Frontier**—higher reliability without sacrificing capability.

*   **Memory isn't Text**: We store information as structured facts (Entities), modeled as connected nodes.
*   **LLMs aren't the Core**: They reason over resolved context, but never own the state or truth.
*   **Context is Deterministic**: No bloated prompts, no token juggling, no surprise amnesia.
*   **Built for Production**: Stable, inspectable, and auditable.

## Next Steps

Start with the fastest path to value:

<CardGroup>
  <Card title="Quickstart" icon="bolt" href="/quickstart">
    Build a Contextual Agent in 2 minutes.
  </Card>
  <Card title="Tutorials" icon="book-open" href="/tutorials/mcp-server">
    Real projects like MCP Servers and N8N integrations.
  </Card>
  <Card title="Migration" icon="arrow-right-arrow-left" href="/migration/mem0">
    Coming from Mem0? See how to upgrade.
  </Card>
</CardGroup>
